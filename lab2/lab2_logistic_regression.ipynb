{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8e0241",
   "metadata": {},
   "source": [
    "# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞ —Ä–æ–±–æ—Ç–∞ ‚Ññ2: –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è\n",
    "\n",
    "## –ú–µ—Ç–∞\n",
    "–†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó \"–∑ –Ω—É–ª—è\" –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –º–µ–¥–∏—á–Ω–∏—Ö —Ç–µ—Å—Ç—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞–Ω–∏—Ö –ø—Ä–æ –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤.\n",
    "\n",
    "## –ó–∞–≤–¥–∞–Ω–Ω—è\n",
    "–î–æ—Å–ª—ñ–¥–∏—Ç–∏ –≤–ø–ª–∏–≤ —Ä—ñ–∑–Ω–∏—Ö –º–µ—Ç–æ–¥—ñ–≤ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó —Ç–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó –Ω–∞ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ.\n",
    "\n",
    "**–î–∞—Ç–∞—Å–µ—Ç**: Healthcare Dataset  \n",
    "**–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞**: Test Results (Normal/Abnormal - –±—ñ–Ω–∞—Ä–Ω–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è)  \n",
    "**–ú–µ—Ç–æ–¥–∏**: SGD —Ç–∞ Mini-batch –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea543a",
   "metadata": {},
   "source": [
    "## 1. –Ü–º–ø–æ—Ä—Ç –±—ñ–±–ª—ñ–æ—Ç–µ–∫ —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94139f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ü–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"‚úÖ –í—Å—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ —É—Å–ø—ñ—à–Ω–æ —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω—ñ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1244fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö\n",
    "df = pd.read_csv('healthcare_dataset.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–û–ì–õ–Ø–î –î–ê–ù–ò–•\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n–†–æ–∑–º—ñ—Ä –¥–∞—Ç–∞—Å–µ—Ç—É: {df.shape[0]} —Ä—è–¥–∫—ñ–≤, {df.shape[1]} —Å—Ç–æ–≤–ø—Ü—ñ–≤\\n\")\n",
    "\n",
    "print(\"–ü–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"–Ü–ù–§–û–†–ú–ê–¶–Ü–Ø –ü–†–û –î–ê–ù–Ü\")\n",
    "print(\"=\" * 70)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ê–Ω–∞–ª—ñ–∑ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó\n",
    "print(\"=\" * 70)\n",
    "print(\"–ê–ù–ê–õ–Ü–ó –¶–Ü–õ–¨–û–í–û–á –ó–ú–Ü–ù–ù–û–á (Test Results)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤:\")\n",
    "print(df['Test Results'].value_counts())\n",
    "\n",
    "print(\"\\n–í—ñ–¥—Å–æ—Ç–∫–æ–≤–µ —Å–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è:\")\n",
    "print(df['Test Results'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# –ì—Ä–∞—Ñ—ñ–∫ 1: Count plot\n",
    "df['Test Results'].value_counts().plot(kind='bar', ax=axes[0], color=['#2E86AB', '#A23B72'])\n",
    "axes[0].set_title('–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ Test Results', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Test Results', fontsize=12)\n",
    "axes[0].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "\n",
    "# –ì—Ä–∞—Ñ—ñ–∫ 2: Pie chart\n",
    "df['Test Results'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                        colors=['#2E86AB', '#A23B72'])\n",
    "axes[1].set_title('–ü—Ä–æ–ø–æ—Ä—Ü—ñ—ó –∫–ª–∞—Å—ñ–≤', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3832e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å\n",
    "print(\"=\" * 70)\n",
    "print(\"–ü–†–û–ü–£–©–ï–ù–Ü –ó–ù–ê–ß–ï–ù–ù–Ø\")\n",
    "print(\"=\" * 70)\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"–ü—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å –Ω–µ–º–∞—î!\")\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤\n",
    "print(f\"\\n–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ab63c",
   "metadata": {},
   "source": [
    "## 2. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ø—ñ—ó –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "df_processed = df.copy()\n",
    "\n",
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±—ñ–Ω–∞—Ä–Ω–æ—ó —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó: Normal = 1, Abnormal/Inconclusive = 0\n",
    "df_processed['Test_Results_Binary'] = (df_processed['Test Results'] == 'Normal').astype(int)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–ö–û–î–£–í–ê–ù–ù–Ø –¶–Ü–õ–¨–û–í–û–á –ó–ú–Ü–ù–ù–û–á\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n–ë—ñ–Ω–∞—Ä–Ω–∞ —Ü—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ —Å—Ç–≤–æ—Ä–µ–Ω–∞:\")\n",
    "print(f\"  Normal ‚Üí 1\")\n",
    "print(f\"  Abnormal/Inconclusive ‚Üí 0\")\n",
    "\n",
    "print(\"\\n–†–æ–∑–ø–æ–¥—ñ–ª:\")\n",
    "print(df_processed['Test_Results_Binary'].value_counts())\n",
    "\n",
    "# –í–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∑–≥—ñ–¥–Ω–æ –∑–∞–≤–¥–∞–Ω–Ω—è)\n",
    "columns_to_drop = ['Name', 'Date of Admission', 'Doctor', 'Hospital', \n",
    "                   'Room Number', 'Discharge Date', 'Test Results']\n",
    "\n",
    "df_processed = df_processed.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"\\n‚úÖ –í–∏–¥–∞–ª–µ–Ω–æ {len(columns_to_drop)} –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "print(f\"–ó–∞–ª–∏—à–∏–ª–æ—Å—å —Å—Ç–æ–≤–ø—Ü—ñ–≤: {df_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö\n",
    "categorical_columns = ['Gender', 'Blood Type', 'Medical Condition', \n",
    "                       'Insurance Provider', 'Admission Type', 'Medication']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ONE-HOT ENCODING –ö–ê–¢–ï–ì–û–†–Ü–ê–õ–¨–ù–ò–• –ó–ú–Ü–ù–ù–ò–•\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_processed, columns=categorical_columns, drop_first=False)\n",
    "\n",
    "print(f\"\\n–ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ –¥–ª—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: {len(categorical_columns)}\")\n",
    "print(f\"–†–æ–∑–º—ñ—Ä –¥–æ –∫–æ–¥—É–≤–∞–Ω–Ω—è: {df_processed.shape}\")\n",
    "print(f\"–†–æ–∑–º—ñ—Ä –ø—ñ—Å–ª—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: {df_encoded.shape}\")\n",
    "print(f\"\\n‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {df_encoded.shape[1] - df_processed.shape[1]} –Ω–æ–≤–∏—Ö –æ–∑–Ω–∞–∫\")\n",
    "\n",
    "print(\"\\n–ü—Ä–∏–∫–ª–∞–¥ –Ω–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫:\")\n",
    "new_cols = [col for col in df_encoded.columns if any(cat in col for cat in categorical_columns)]\n",
    "print(new_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–±—ñ—Ä –æ–∑–Ω–∞–∫ —Ç–∞ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó\n",
    "X = df_encoded.drop('Test_Results_Binary', axis=1).values\n",
    "y = df_encoded['Test_Results_Binary'].values\n",
    "\n",
    "feature_names = df_encoded.drop('Test_Results_Binary', axis=1).columns.tolist()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–ü–Ü–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ò–• –î–õ–Ø –ú–û–î–ï–õ–Æ–í–ê–ù–ù–Ø\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n–ú–∞—Ç—Ä–∏—Ü—è –æ–∑–Ω–∞–∫ X: {X.shape}\")\n",
    "print(f\"–í–µ–∫—Ç–æ—Ä —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó y: {y.shape}\")\n",
    "print(f\"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {X.shape[1]}\")\n",
    "print(f\"–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω—å: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥—ñ–ª –Ω–∞ train/val/test (60%/20%/20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–ü–û–î–Ü–õ –î–ê–ù–ò–•\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n–¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∞ –≤–∏–±—ñ—Ä–∫–∞: {X_train.shape[0]} ({X_train.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"–í–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∞ –≤–∏–±—ñ—Ä–∫–∞: {X_val.shape[0]} ({X_val.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"–¢–µ—Å—Ç–æ–≤–∞ –≤–∏–±—ñ—Ä–∫–∞: {X_test.shape[0]} ({X_test.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ —É –≤–∏–±—ñ—Ä–∫–∞—Ö:\")\n",
    "print(f\"  Train: {np.bincount(y_train)}\")\n",
    "print(f\"  Val:   {np.bincount(y_val)}\")\n",
    "print(f\"  Test:  {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —á–∏—Å–ª–æ–≤–∏—Ö –æ–∑–Ω–∞–∫\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# –î–æ–¥–∞–≤–∞–Ω–Ω—è intercept (—Å—Ç–æ–≤–ø—á–∏–∫ –æ–¥–∏–Ω–∏—Ü—å)\n",
    "X_train_final = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
    "X_val_final = np.c_[np.ones(X_val_scaled.shape[0]), X_val_scaled]\n",
    "X_test_final = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–ù–û–†–ú–ê–õ–Ü–ó–ê–¶–Ü–Ø –¢–ê –î–û–î–ê–í–ê–ù–ù–Ø INTERCEPT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nX_train_final (–∑ intercept): {X_train_final.shape}\")\n",
    "print(f\"X_val_final (–∑ intercept): {X_val_final.shape}\")\n",
    "print(f\"X_test_final (–∑ intercept): {X_test_final.shape}\")\n",
    "print(\"\\n‚úÖ –î–∞–Ω—ñ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7110439",
   "metadata": {},
   "source": [
    "## 3. –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –∑ –Ω—É–ª—è\n",
    "\n",
    "### –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∞ –º–æ–¥–µ–ª—å:\n",
    "\n",
    "**–°–∏–≥–º–æ—ó–¥–∞**: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "**–ü—Ä–æ–≥–Ω–æ–∑**: $\\hat{y} = \\sigma(X\\theta)$\n",
    "\n",
    "**–§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç (Log Loss)**: $J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(\\hat{y}^{(i)}) + (1-y^{(i)}) \\log(1-\\hat{y}^{(i)})]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ccba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó\n",
    "def sigmoid(z):\n",
    "    \"\"\"–°–∏–≥–º–æ—ó–¥–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))  # clip –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ\n",
    "\n",
    "def compute_loss(X, y, weights, lambda_reg=0, reg_type=None):\n",
    "    \"\"\"\n",
    "    –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç (Log Loss) –∑ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—é —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\n",
    "    \n",
    "    Parameters:\n",
    "    - X: –º–∞—Ç—Ä–∏—Ü—è –æ–∑–Ω–∞–∫\n",
    "    - y: —Ü—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞\n",
    "    - weights: –≤–µ–∫—Ç–æ—Ä –≤–∞–≥\n",
    "    - lambda_reg: –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\n",
    "    - reg_type: —Ç–∏–ø —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó ('l1', 'l2' –∞–±–æ None)\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    h = sigmoid(X.dot(weights))\n",
    "    \n",
    "    # –£–Ω–∏–∫–Ω–µ–Ω–Ω—è log(0)\n",
    "    h = np.clip(h, 1e-10, 1 - 1e-10)\n",
    "    \n",
    "    # Binary Cross-Entropy Loss\n",
    "    loss = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    \n",
    "    # –î–æ–¥–∞–≤–∞–Ω–Ω—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó (intercept –Ω–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑—É—î—Ç—å—Å—è)\n",
    "    if reg_type == 'l2' and lambda_reg > 0:\n",
    "        loss += (lambda_reg / (2 * m)) * np.sum(weights[1:] ** 2)\n",
    "    elif reg_type == 'l1' and lambda_reg > 0:\n",
    "        loss += (lambda_reg / m) * np.sum(np.abs(weights[1:]))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def predict(X, weights):\n",
    "    \"\"\"–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫–ª–∞—Å—ñ–≤\"\"\"\n",
    "    probabilities = sigmoid(X.dot(weights))\n",
    "    return (probabilities >= 0.5).astype(int), probabilities\n",
    "\n",
    "print(\"‚úÖ –§—É–Ω–∫—Ü—ñ—ó sigmoid, compute_loss —Ç–∞ predict –≤–∏–∑–Ω–∞—á–µ–Ω—ñ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069290ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü—ñ—è –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫—É (SGD —Ç–∞ Mini-batch)\n",
    "def train_logistic_regression(X_train, y_train, X_val, y_val, \n",
    "                               learning_rate=0.01, epochs=1000, \n",
    "                               batch_size=None, lambda_reg=0, reg_type=None,\n",
    "                               patience=10, verbose=True):\n",
    "    \"\"\"\n",
    "    –ù–∞–≤—á–∞–Ω–Ω—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó\n",
    "    \n",
    "    Parameters:\n",
    "    - batch_size: None –¥–ª—è —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ–≥–æ (SGD), —á–∏—Å–ª–æ –¥–ª—è mini-batch\n",
    "    - lambda_reg: –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\n",
    "    - reg_type: 'l1', 'l2' –∞–±–æ None\n",
    "    - patience: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö –±–µ–∑ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –¥–ª—è —Ä–∞–Ω–Ω—å–æ–≥–æ –∑—É–ø–∏–Ω–µ–Ω–Ω—è\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    m, n = X_train.shape\n",
    "    weights = np.zeros(n)  # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∞–≥\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_weights = None\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É –±–∞—Ç—á–∞\n",
    "    if batch_size is None:  # SGD\n",
    "        batch_size = 1\n",
    "        method = \"SGD\"\n",
    "    else:  # Mini-batch\n",
    "        method = f\"Mini-batch ({batch_size})\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # –ü–µ—Ä–µ–º—ñ—à—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X_train[indices]\n",
    "        y_shuffled = y_train[indices]\n",
    "        \n",
    "        # –ù–∞–≤—á–∞–Ω–Ω—è –ø–æ –±–∞—Ç—á–∞—Ö\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å\n",
    "            h = sigmoid(X_batch.dot(weights))\n",
    "            \n",
    "            # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –≥—Ä–∞–¥—ñ—î–Ω—Ç–∞\n",
    "            gradient = (1/len(y_batch)) * X_batch.T.dot(h - y_batch)\n",
    "            \n",
    "            # –î–æ–¥–∞–≤–∞–Ω–Ω—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó –¥–æ –≥—Ä–∞–¥—ñ—î–Ω—Ç–∞\n",
    "            if reg_type == 'l2' and lambda_reg > 0:\n",
    "                gradient[1:] += (lambda_reg / len(y_batch)) * weights[1:]\n",
    "            elif reg_type == 'l1' and lambda_reg > 0:\n",
    "                gradient[1:] += (lambda_reg / len(y_batch)) * np.sign(weights[1:])\n",
    "            \n",
    "            # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –≤–∞–≥\n",
    "            weights -= learning_rate * gradient\n",
    "        \n",
    "        # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –≤—Ç—Ä–∞—Ç –ø—ñ—Å–ª—è –µ–ø–æ—Ö–∏\n",
    "        train_loss = compute_loss(X_train, y_train, weights, lambda_reg, reg_type)\n",
    "        val_loss = compute_loss(X_val, y_val, weights, lambda_reg, reg_type)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_weights = weights.copy()\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping –Ω–∞ –µ–ø–æ—Å—ñ {epoch + 1}\")\n",
    "            break\n",
    "        \n",
    "        # –í–∏–≤–µ–¥–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É\n",
    "        if verbose and (epoch + 1) % 100 == 0:\n",
    "            print(f\"–ï–ø–æ—Ö–∞ {epoch + 1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n‚úÖ –ù–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ ({method})\")\n",
    "        print(f\"–ù–∞–π–∫—Ä–∞—â–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∞ –≤—Ç—Ä–∞—Ç–∞: {best_val_loss:.4f} –Ω–∞ –µ–ø–æ—Å—ñ {best_epoch + 1}\")\n",
    "    \n",
    "    return best_weights, train_losses, val_losses\n",
    "\n",
    "print(\"‚úÖ –§—É–Ω–∫—Ü—ñ—è train_logistic_regression –≤–∏–∑–Ω–∞—á–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64ef5d",
   "metadata": {},
   "source": [
    "## 4. –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π\n",
    "\n",
    "### 4.1. –ú–æ–¥–µ–ª—å –∑—ñ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–∏–º –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–º —Å–ø—É—Å–∫–æ–º (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549eb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ SGD –±–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\n",
    "print(\"=\" * 70)\n",
    "print(\"–ù–ê–í–ß–ê–ù–ù–Ø –ú–û–î–ï–õ–Ü: –°–¢–û–•–ê–°–¢–ò–ß–ù–ò–ô –ì–†–ê–î–Ü–Ñ–ù–¢–ù–ò–ô –°–ü–£–°–ö (SGD)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "weights_sgd, train_losses_sgd, val_losses_sgd = train_logistic_regression(\n",
    "    X_train_final, y_train, X_val_final, y_val,\n",
    "    learning_rate=0.01,\n",
    "    epochs=1000,\n",
    "    batch_size=None,  # SGD\n",
    "    lambda_reg=0,\n",
    "    reg_type=None,\n",
    "    patience=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373eb09",
   "metadata": {},
   "source": [
    "### 4.2. –ú–æ–¥–µ–ª—å –∑ Mini-batch –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–º —Å–ø—É—Å–∫–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ Mini-batch –±–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\n",
    "print(\"=\" * 70)\n",
    "print(\"–ù–ê–í–ß–ê–ù–ù–Ø –ú–û–î–ï–õ–Ü: MINI-BATCH –ì–†–ê–î–Ü–Ñ–ù–¢–ù–ò–ô –°–ü–£–°–ö\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "weights_minibatch, train_losses_minibatch, val_losses_minibatch = train_logistic_regression(\n",
    "    X_train_final, y_train, X_val_final, y_val,\n",
    "    learning_rate=0.01,\n",
    "    epochs=1000,\n",
    "    batch_size=32,  # Mini-batch\n",
    "    lambda_reg=0,\n",
    "    reg_type=None,\n",
    "    patience=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a0264",
   "metadata": {},
   "source": [
    "## 5. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫—Ä–∏–≤–∏—Ö –Ω–∞–≤—á–∞–Ω–Ω—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫—Ä–∏–≤–∏—Ö –Ω–∞–≤—á–∞–Ω–Ω—è\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# SGD\n",
    "axes[0].plot(train_losses_sgd, label='Train Loss', linewidth=2, color='#2E86AB')\n",
    "axes[0].plot(val_losses_sgd, label='Validation Loss', linewidth=2, color='#A23B72')\n",
    "axes[0].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('SGD: –ö—Ä–∏–≤—ñ –Ω–∞–≤—á–∞–Ω–Ω—è', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mini-batch\n",
    "axes[1].plot(train_losses_minibatch, label='Train Loss', linewidth=2, color='#2E86AB')\n",
    "axes[1].plot(val_losses_minibatch, label='Validation Loss', linewidth=2, color='#A23B72')\n",
    "axes[1].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title('Mini-batch: –ö—Ä–∏–≤—ñ –Ω–∞–≤—á–∞–Ω–Ω—è', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ –û–±–∏–¥–≤—ñ –º–æ–¥–µ–ª—ñ —É—Å–ø—ñ—à–Ω–æ –Ω–∞–≤—á–µ–Ω—ñ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a76c7c",
   "metadata": {},
   "source": [
    "## 6. –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –º–æ–¥–µ–ª—ñ\n",
    "def evaluate_model(X_test, y_test, weights, model_name):\n",
    "    \"\"\"–û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö\"\"\"\n",
    "    y_pred, y_proba = predict(X_test, weights)\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# –û—Ü—ñ–Ω–∫–∞ –æ–±–æ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "results_sgd = evaluate_model(X_test_final, y_test, weights_sgd, \"SGD –±–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\")\n",
    "results_minibatch = evaluate_model(X_test_final, y_test, weights_minibatch, \"Mini-batch –±–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# SGD Confusion Matrix\n",
    "sns.heatmap(results_sgd['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Abnormal (0)', 'Normal (1)'],\n",
    "            yticklabels=['Abnormal (0)', 'Normal (1)'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_title('SGD: Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "# Mini-batch Confusion Matrix\n",
    "sns.heatmap(results_minibatch['confusion_matrix'], annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Abnormal (0)', 'Normal (1)'],\n",
    "            yticklabels=['Abnormal (0)', 'Normal (1)'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_title('Mini-batch: Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce693e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –º–µ—Ç—Ä–∏–∫\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        '–ú–µ—Ç–æ–¥': 'SGD',\n",
    "        'Accuracy': results_sgd['accuracy'],\n",
    "        'Precision': results_sgd['precision'],\n",
    "        'Recall': results_sgd['recall'],\n",
    "        'F1-Score': results_sgd['f1']\n",
    "    },\n",
    "    {\n",
    "        '–ú–µ—Ç–æ–¥': 'Mini-batch (32)',\n",
    "        'Accuracy': results_minibatch['accuracy'],\n",
    "        'Precision': results_minibatch['precision'],\n",
    "        'Recall': results_minibatch['recall'],\n",
    "        'F1-Score': results_minibatch['f1']\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–ü–û–†–Ü–í–ù–Ø–õ–¨–ù–ê –¢–ê–ë–õ–ò–¶–Ø –ú–ï–¢–†–ò–ö\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è\n",
    "comparison_df.set_index('–ú–µ—Ç–æ–¥')[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(\n",
    "    kind='bar', figsize=(12, 6), rot=0, width=0.8\n",
    ")\n",
    "plt.title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç—Ä–∏–∫: SGD vs Mini-batch', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('–ó–Ω–∞—á–µ–Ω–Ω—è', fontsize=12)\n",
    "plt.xlabel('–ú–µ—Ç–æ–¥', fontsize=12)\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='best')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49892e33",
   "metadata": {},
   "source": [
    "## 7. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è (L1 —Ç–∞ L2) - –î–æ–¥–∞—Ç–∫–æ–≤–µ –∑–∞–≤–¥–∞–Ω–Ω—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc23c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—î—é\n",
    "print(\"=\" * 70)\n",
    "print(\"–ù–ê–í–ß–ê–ù–ù–Ø –ó –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–Ü–Ñ–Æ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è (Ridge)\n",
    "print(\"\\nüìä L2 (Ridge) —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è...\")\n",
    "weights_l2, train_l2, val_l2 = train_logistic_regression(\n",
    "    X_train_final, y_train, X_val_final, y_val,\n",
    "    learning_rate=0.01, epochs=1000, batch_size=32,\n",
    "    lambda_reg=0.1, reg_type='l2', patience=10, verbose=False\n",
    ")\n",
    "\n",
    "# L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è (Lasso)\n",
    "print(\"üìä L1 (Lasso) —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è...\")\n",
    "weights_l1, train_l1, val_l1 = train_logistic_regression(\n",
    "    X_train_final, y_train, X_val_final, y_val,\n",
    "    learning_rate=0.01, epochs=1000, batch_size=32,\n",
    "    lambda_reg=0.1, reg_type='l1', patience=10, verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ –ú–æ–¥–µ–ª—ñ –∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—î—é –Ω–∞–≤—á–µ–Ω—ñ!\")\n",
    "\n",
    "# –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—î—é\n",
    "results_l2 = evaluate_model(X_test_final, y_test, weights_l2, \"Mini-batch –∑ L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—î—é\")\n",
    "results_l1 = evaluate_model(X_test_final, y_test, weights_l1, \"Mini-batch –∑ L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—î—é\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8277de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—ñ–Ω–∞–ª—å–Ω–∞ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "final_comparison = pd.DataFrame([\n",
    "    {'–ú–æ–¥–µ–ª—å': 'SGD', 'Accuracy': results_sgd['accuracy'], 'Precision': results_sgd['precision'], \n",
    "     'Recall': results_sgd['recall'], 'F1-Score': results_sgd['f1']},\n",
    "    {'–ú–æ–¥–µ–ª—å': 'Mini-batch', 'Accuracy': results_minibatch['accuracy'], 'Precision': results_minibatch['precision'],\n",
    "     'Recall': results_minibatch['recall'], 'F1-Score': results_minibatch['f1']},\n",
    "    {'–ú–æ–¥–µ–ª—å': 'Mini-batch + L2', 'Accuracy': results_l2['accuracy'], 'Precision': results_l2['precision'],\n",
    "     'Recall': results_l2['recall'], 'F1-Score': results_l2['f1']},\n",
    "    {'–ú–æ–¥–µ–ª—å': 'Mini-batch + L1', 'Accuracy': results_l1['accuracy'], 'Precision': results_l1['precision'],\n",
    "     'Recall': results_l1['recall'], 'F1-Score': results_l1['f1']}\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"–§–Ü–ù–ê–õ–¨–ù–ê –ü–û–†–Ü–í–ù–Ø–õ–¨–ù–ê –¢–ê–ë–õ–ò–¶–Ø –í–°–Ü–• –ú–û–î–ï–õ–ï–ô\")\n",
    "print(\"=\" * 80)\n",
    "print(final_comparison.to_string(index=False))\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "final_comparison.set_index('–ú–æ–¥–µ–ª—å').plot(kind='bar', figsize=(14, 6), rot=45, width=0.8)\n",
    "plt.title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('–ó–Ω–∞—á–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫', fontsize=12)\n",
    "plt.xlabel('–ú–æ–¥–µ–ª—å', fontsize=12)\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4df9a",
   "metadata": {},
   "source": [
    "## 8. –í–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ –∞–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"–í–ò–°–ù–û–í–ö–ò –¢–ê –ê–ù–ê–õ–Ü–ó –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø SGD vs Mini-batch GRADIENT DESCENT:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   ‚Ä¢ SGD - —à–≤–∏–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è, –∞–ª–µ –±—ñ–ª—å—à–∞ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å —É loss —Ñ—É–Ω–∫—Ü—ñ—ó\")\n",
    "print(f\"   ‚Ä¢ Mini-batch - —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å, –∫—Ä–∞—â–∞ –≥–µ–Ω–µ—Ä–∞–ª—ñ–∑–∞—Ü—ñ—è\")\n",
    "print(f\"   ‚Ä¢ –†—ñ–∑–Ω–∏—Ü—è –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö: Œî Accuracy = {abs(results_sgd['accuracy'] - results_minibatch['accuracy']):.4f}\")\n",
    "\n",
    "print(\"\\n2. –í–ü–õ–ò–í –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–Ü–á:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   ‚Ä¢ L2 (Ridge) —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è:\")\n",
    "print(f\"     - –ó–º–µ–Ω—à—É—î –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω—è —á–µ—Ä–µ–∑ —à—Ç—Ä–∞—Ñ –Ω–∞ –≤–µ–ª–∏–∫—ñ –≤–∞–≥–∏\")\n",
    "print(f\"     - Accuracy: {results_l2['accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ L1 (Lasso) —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è:\")\n",
    "print(f\"     - –í–∏–∫–æ–Ω—É—î feature selection —á–µ—Ä–µ–∑ –∑–∞–Ω—É–ª—ñ–Ω–Ω—è –≤–∞–≥\")\n",
    "print(f\"     - Accuracy: {results_l1['accuracy']:.4f}\")\n",
    "print(f\"     - –ö—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–µ–Ω—É–ª—å–æ–≤–∏—Ö –≤–∞–≥: {np.sum(np.abs(weights_l1) > 1e-4)}\")\n",
    "\n",
    "print(\"\\n3. –ù–ê–ô–ö–†–ê–©–ê –ú–û–î–ï–õ–¨:\")\n",
    "print(\"-\" * 80)\n",
    "best_model = final_comparison.loc[final_comparison['F1-Score'].idxmax(), '–ú–æ–¥–µ–ª—å']\n",
    "best_f1 = final_comparison['F1-Score'].max()\n",
    "print(f\"   ‚Ä¢ {best_model} –∑ F1-Score = {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n4. –ó–ê–ì–ê–õ–¨–ù–Ü –í–ò–°–ù–û–í–ö–ò:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   ‚Ä¢ –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è –¥–æ–±—Ä–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –º–µ–¥–∏—á–Ω–∏—Ö —Ç–µ—Å—Ç—ñ–≤\")\n",
    "print(\"   ‚Ä¢ Mini-batch gradient descent –∑–∞–±–µ–∑–ø–µ—á—É—î –∫—Ä–∞—â–∏–π –±–∞–ª–∞–Ω—Å —à–≤–∏–¥–∫–æ—Å—Ç—ñ/—Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ\")\n",
    "print(\"   ‚Ä¢ –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –ø–æ–∫—Ä–∞—â—É—î —É–∑–∞–≥–∞–ª—å–Ω—é—é—á—É –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ\")\n",
    "print(\"   ‚Ä¢ Early stopping –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∑–∞–ø–æ–±—ñ–≥–∞—î –ø–µ—Ä–µ–æ–±—É—á–∞–Ω–Ω—é\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed48710",
   "metadata": {},
   "source": [
    "## 9. –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4182e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–∫—Ä–∞—â–µ–Ω–∞ –º–æ–¥–µ–ª—å –∑ –≤–∏—â–∏–º learning rate —Ç–∞ –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–º–∏ –∫–ª–∞—Å–∞–º–∏\n",
    "print(\"=\" * 80)\n",
    "print(\"–ü–ï–†–ï–ù–ê–í–ß–ê–ù–ù–Ø –ó –ü–Ü–î–í–ò–©–ï–ù–ò–ú LEARNING RATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –°–ø—Ä–æ–±–∞ –∑ –≤–∏—â–∏–º learning rate\n",
    "weights_minibatch_v2, train_losses_v2, val_losses_v2 = train_logistic_regression(\n",
    "    X_train_final, y_train, X_val_final, y_val,\n",
    "    learning_rate=0.1,  # –ó–±—ñ–ª—å—à–µ–Ω–æ –∑ 0.01\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    lambda_reg=0.0,\n",
    "    reg_type=None,\n",
    "    patience=15,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# –û—Ü—ñ–Ω–∫–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ\n",
    "results_minibatch_v2 = evaluate_model(X_test_final, y_test, weights_minibatch_v2, \"Mini-batch (LR=0.1)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"–ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –†–Ü–ó–ù–ò–• LEARNING RATES\")\n",
    "print(\"=\" * 80)\n",
    "comparison_lr = pd.DataFrame([\n",
    "    {'Learning Rate': 0.01, 'Accuracy': results_minibatch['accuracy'], \n",
    "     'Precision': results_minibatch['precision'], 'Recall': results_minibatch['recall'], \n",
    "     'F1-Score': results_minibatch['f1']},\n",
    "    {'Learning Rate': 0.1, 'Accuracy': results_minibatch_v2['accuracy'], \n",
    "     'Precision': results_minibatch_v2['precision'], 'Recall': results_minibatch_v2['recall'], \n",
    "     'F1-Score': results_minibatch_v2['f1']}\n",
    "])\n",
    "print(comparison_lr.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf245d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∞–≥ —Ç–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å\n",
    "print(\"=\" * 80)\n",
    "print(\"–î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–ï–õ–Ü\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∞–≥\n",
    "print(f\"\\n–í–∞–≥–∏ SGD (–ø–µ—Ä—à—ñ 10): {weights_sgd[:10]}\")\n",
    "print(f\"–í–∞–≥–∏ Mini-batch (–ø–µ—Ä—à—ñ 10): {weights_minibatch[:10]}\")\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏—Ö –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π\n",
    "probs_sgd = sigmoid(X_test_final @ weights_sgd)\n",
    "probs_mb = sigmoid(X_test_final @ weights_minibatch)\n",
    "\n",
    "print(f\"\\nSGD - –ú—ñ–Ω –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å: {probs_sgd.min():.4f}, –ú–∞–∫—Å: {probs_sgd.max():.4f}\")\n",
    "print(f\"Mini-batch - –ú—ñ–Ω –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å: {probs_mb.min():.4f}, –ú–∞–∫—Å: {probs_mb.max():.4f}\")\n",
    "\n",
    "print(f\"\\nSGD - –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å > 0.5: {(probs_sgd > 0.5).sum()}\")\n",
    "print(f\"Mini-batch - –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å > 0.5: {(probs_mb > 0.5).sum()}\")\n",
    "\n",
    "# –°–ø—Ä–æ–±—É—î–º–æ –∑ –Ω–∏–∂—á–∏–º –ø–æ—Ä–æ–≥–æ–º –¥–ª—è mini-batch\n",
    "threshold = 0.3\n",
    "preds_mb_low = (probs_mb >= threshold).astype(int)\n",
    "print(f\"\\n–ú—ñ–Ω—ñ-batch –∑ –ø–æ—Ä–æ–≥–æ–º {threshold}:\")\n",
    "print(f\"  –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å –∫–ª–∞—Å—É 1: {preds_mb_low.sum()}\")\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(probs_sgd, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(x=0.5, color='red', linestyle='--', label='–ü–æ—Ä—ñ–≥ 0.5')\n",
    "axes[0].set_title('SGD: –†–æ–∑–ø–æ–¥—ñ–ª –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏—Ö –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π')\n",
    "axes[0].set_xlabel('–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å')\n",
    "axes[0].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(probs_mb, bins=50, alpha=0.7, edgecolor='black', color='green')\n",
    "axes[1].axvline(x=0.5, color='red', linestyle='--', label='–ü–æ—Ä—ñ–≥ 0.5')\n",
    "axes[1].set_title('Mini-batch: –†–æ–∑–ø–æ–¥—ñ–ª –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏—Ö –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π')\n",
    "axes[1].set_xlabel('–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å')\n",
    "axes[1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ebab9",
   "metadata": {},
   "source": [
    "### –ü–æ—è—Å–Ω–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n",
    "\n",
    "**–ß–æ–º—É Mini-batch –ø–µ—Ä–µ–¥–±–∞—á–∞—î —Ç—ñ–ª—å–∫–∏ –∫–ª–∞—Å 0?**\n",
    "\n",
    "–ó –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –≤–∏–¥–Ω–æ, —â–æ:\n",
    "- **SGD**: –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –≤—ñ–¥ 0.16 –¥–æ 0.58 ‚Üí –¥–µ—è–∫—ñ –ø–µ—Ä–µ–≤–∏—â—É—é—Ç—å –ø–æ—Ä—ñ–≥ 0.5\n",
    "- **Mini-batch**: –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –≤—ñ–¥ 0.28 –¥–æ 0.39 ‚Üí **–∂–æ–¥–Ω–∞ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É—î 0.5**\n",
    "\n",
    "**–ü—Ä–∏—á–∏–Ω–∏:**\n",
    "1. **–ù–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç**: –∫–ª–∞—Å 0 (Abnormal/Inconclusive) —Å—Ç–∞–Ω–æ–≤–∏—Ç—å 67%, –∫–ª–∞—Å 1 (Normal) - –ª–∏—à–µ 33%\n",
    "2. **Mini-batch –±—ñ–ª—å—à –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∏–π**: —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å –ø—Ä–∏–∑–≤–æ–¥–∏—Ç—å –¥–æ –Ω–∏–∂—á–∏—Ö –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π\n",
    "3. **SGD –±—ñ–ª—å—à –∞–≥—Ä–µ—Å–∏–≤–Ω–∏–π**: –≤–∏—Å–æ–∫–∞ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å –¥–æ–∑–≤–æ–ª—è—î –¥–µ—è–∫–∏–º –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º –ø–µ—Ä–µ–≤–∏—â–∏—Ç–∏ 0.5\n",
    "\n",
    "**–ú–æ–∂–ª–∏–≤—ñ —Ä—ñ—à–µ–Ω–Ω—è:**\n",
    "- –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∑–≤–∞–∂–µ–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é –≤—Ç—Ä–∞—Ç (class weights)\n",
    "- –ó–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ SMOTE –∞–±–æ —ñ–Ω—à—ñ –º–µ—Ç–æ–¥–∏ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è\n",
    "- –ó–Ω–∏–∑–∏—Ç–∏ –ø–æ—Ä—ñ–≥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–æ 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84480e9b",
   "metadata": {},
   "source": [
    "## 10. –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –æ–∑–Ω–∞–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –¥–ª—è –æ–±—Ä–∞–Ω–∏—Ö —á–∏—Å–ª–æ–≤–∏—Ö –æ–∑–Ω–∞–∫\n",
    "# –í—ñ–∑—å–º–µ–º–æ –ø—ñ–¥–≤–∏–±—ñ—Ä–∫—É –¥–ª—è –∫—Ä–∞—â–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó\n",
    "numeric_features = ['Age', 'Billing Amount']\n",
    "selected_categorical = ['Gender_Female', 'Gender_Male',\n",
    "                        'Blood Type_A+', 'Blood Type_O+']\n",
    "feature_subset = numeric_features + selected_categorical + ['Test_Results_Binary']\n",
    "\n",
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ –≤–∏–±—Ä–∞–Ω–∏–º–∏ –æ–∑–Ω–∞–∫–∞–º–∏\n",
    "subset_data = df_encoded[feature_subset].copy()\n",
    "\n",
    "# –û–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–æ—ó –º–∞—Ç—Ä–∏—Ü—ñ\n",
    "correlation_matrix = subset_data.corr()\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –æ–∑–Ω–∞–∫', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"–ù–ê–ô–°–ò–õ–¨–ù–Ü–®–Ü –ö–û–†–ï–õ–Ø–¶–Ü–á –ó –¶–Ü–õ–¨–û–í–û–Æ –ó–ú–Ü–ù–ù–û–Æ\")\n",
    "print(\"=\" * 80)\n",
    "target_corr = correlation_matrix['Test_Results_Binary'].drop('Test_Results_Binary').abs().sort_values(ascending=False)\n",
    "print(target_corr.to_string())\n",
    "print(\"\\n‚úÖ –í—Å—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥—É–∂–µ —Å–ª–∞–±–∫—ñ (< 0.05), —â–æ –ø–æ—è—Å–Ω—é—î —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72162fbd",
   "metadata": {},
   "source": [
    "## 11. –ü—ñ–¥—Å—É–º–æ–∫ —Ä–æ–±–æ—Ç–∏\n",
    "\n",
    "### –í–∏–∫–æ–Ω–∞–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è:\n",
    "\n",
    "1. ‚úÖ **–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö** \n",
    "   - –î–∞—Ç–∞—Å–µ—Ç: 55,500 –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤ –∑ –º–µ–¥–∏—á–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏\n",
    "   - –°—Ç–≤–æ—Ä–µ–Ω–∞ –±—ñ–Ω–∞—Ä–Ω–∞ —Ü—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ (Normal vs Abnormal/Inconclusive)\n",
    "   - –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤: 67% –∫–ª–∞—Å 0, 33% –∫–ª–∞—Å 1\n",
    "\n",
    "2. ‚úÖ **–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö**\n",
    "   - One-hot encoding –¥–ª—è 6 –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö\n",
    "   - –†–æ–∑–ø–æ–¥—ñ–ª: 60% train / 20% validation / 20% test (—Å—Ç—Ä–∞—Ç–∏—Ñ—ñ–∫–æ–≤–∞–Ω–∏–π)\n",
    "   - StandardScaler –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "\n",
    "3. ‚úÖ **–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –∑ –Ω—É–ª—è**\n",
    "   - Sigmoid —Ñ—É–Ω–∫—Ü—ñ—è –∑ numerical stability\n",
    "   - Binary Cross-Entropy (Log Loss) —Ñ—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç\n",
    "   - SGD —Ç–∞ Mini-batch gradient descent\n",
    "   - Early stopping (patience=10)\n",
    "\n",
    "4. ‚úÖ **–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó**\n",
    "   - **SGD**: –±—ñ–ª—å—à –∞–≥—Ä–µ—Å–∏–≤–Ω–∏–π, –¥–µ—è–∫—ñ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è (F1=0.026)\n",
    "   - **Mini-batch**: –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ñ—à–∏–π, —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å (Accuracy=66.6%)\n",
    "\n",
    "5. ‚úÖ **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è**\n",
    "   - L2 (Ridge) —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –∑ Œª=0.1\n",
    "   - L1 (Lasso) —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –∑ Œª=0.1\n",
    "\n",
    "6. ‚úÖ **–û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π**\n",
    "   - Confusion matrices\n",
    "   - Accuracy, Precision, Recall, F1-Score\n",
    "   - Learning curves\n",
    "\n",
    "7. ‚úÖ **–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∏–π –∞–Ω–∞–ª—ñ–∑**\n",
    "   - –í–∏—è–≤–ª–µ–Ω–æ –¥—É–∂–µ —Å–ª–∞–±–∫—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∑ —Ü—ñ–ª—å–æ–≤–æ—é –∑–º—ñ–Ω–Ω–æ—é (< 0.01)\n",
    "   - –ü–æ—è—Å–Ω—é—î —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó\n",
    "\n",
    "### –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏:\n",
    "\n",
    "- **–ü—Ä–æ–±–ª–µ–º–∞ –Ω–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ—Å—Ç—ñ**: –¥–∞—Ç–∞—Å–µ—Ç –º–∞—î —Å–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è 2:1, —â–æ –≤–ø–ª–∏–≤–∞—î –Ω–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è\n",
    "- **SGD –±—ñ–ª—å—à —á—É—Ç–ª–∏–≤–∏–π**: –≤–∏—Å–æ–∫—ñ –≥—Ä–∞–¥—ñ—î–Ω—Ç–∏ –¥–æ–∑–≤–æ–ª—è—é—Ç—å –¥–µ—è–∫–∏–º –ø—Ä–æ–≥–Ω–æ–∑–∞–º –ø–µ—Ä–µ–≤–∏—â–∏—Ç–∏ –ø–æ—Ä—ñ–≥ 0.5\n",
    "- **Mini-batch —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∏–π**: –∞–ª–µ –º–æ–∂–µ –±—É—Ç–∏ –∑–∞–Ω–∞–¥—Ç–æ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∏–º –¥–ª—è –º–µ–Ω—à–∏–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—É\n",
    "- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –Ω–µ –≤–∏—Ä—ñ—à—É—î –ø—Ä–æ–±–ª–µ–º—É**: –ø–æ—Ç—Ä—ñ–±–Ω—ñ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –º–µ—Ç–æ–¥–∏ (class weights, SMOTE, threshold tuning)\n",
    "- **–°–ª–∞–±–∫—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó**: features –º–∞—é—Ç—å –¥—É–∂–µ —Å–ª–∞–±–∫–∏–π –∑–≤'—è–∑–æ–∫ –∑ target, —â–æ —É—Å–∫–ª–∞–¥–Ω—é—î –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
